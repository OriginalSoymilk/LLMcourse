# query_faiss.py
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import pickle
import os
# åˆå§‹åŒ–ï¼šåªåœ¨ç¬¬ä¸€æ¬¡èª¿ç”¨æ™‚è¼‰å…¥
model = None
index = None
documents = None

def load_resources():
    global model, index, documents
    print("ğŸ“‚ ç•¶å‰ç›®éŒ„ï¼š", os.getcwd())
    print("ğŸ“ æª”æ¡ˆåˆ—è¡¨ï¼š", os.listdir("."))

    if model is None:
        model = SentenceTransformer('all-MiniLM-L6-v2')

    if index is None:
        try:
            print("Loading faiss...")
            index = faiss.read_index("nutrition_index.faiss")
            print("faiss success")
        except Exception as e:
            print("âŒ FAISS è¼‰å…¥å¤±æ•—ï¼š", e)

    if documents is None:
        try:
            print("Loading pkl")
            with open("nutrition_docs.pkl", "rb") as f:
                documents = pickle.load(f)
            print("pkl success")
        except Exception as e:
            print("âŒ PKL è¼‰å…¥å¤±æ•—ï¼š", e)

def search_similar_documents(query: str, top_k: int = 10) -> str:
    print("ğŸ” å‘¼å« search_similar_documents()")
    load_resources()
    embedding = model.encode([query])
    D, I = index.search(np.array(embedding), k=top_k)
    relevant_docs = [documents[i] for i in I[0]]
    print("æŸ¥è©¢ queryï¼š", query)
    print("æ‰¾åˆ°æ–‡ä»¶ï¼š", relevant_docs)
    return "\n".join(relevant_docs)
